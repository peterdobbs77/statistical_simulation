{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying Binary Image Classification\n",
    "Let's investigate the image set, simply by differentiating between images with 'No Finding' set to 1 from those without that setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load `train.csv` and `valid.csv` files. Note: here, you'll notice that I have `train_plusMeta.csv`, which is a modified version of the original file to include PID and StudyID as separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Path</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Frontal/Lateral</th>\n",
       "      <th>AP/PA</th>\n",
       "      <th>No Finding</th>\n",
       "      <th>Enlarged Cardiomediastinum</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Lung Opacity</th>\n",
       "      <th>Lung Lesion</th>\n",
       "      <th>...</th>\n",
       "      <th>Consolidation</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Atelectasis</th>\n",
       "      <th>Pneumothorax</th>\n",
       "      <th>Pleural Effusion</th>\n",
       "      <th>Pleural Other</th>\n",
       "      <th>Fracture</th>\n",
       "      <th>Support Devices</th>\n",
       "      <th>PID</th>\n",
       "      <th>StudyID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CheXpert-v1.0-small/valid/patient64541/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>73</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64541</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CheXpert-v1.0-small/valid/patient64542/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>70</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>PA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64542</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>CheXpert-v1.0-small/valid/patient64543/study1/...</td>\n",
       "      <td>Male</td>\n",
       "      <td>85</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64543</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>CheXpert-v1.0-small/valid/patient64544/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64544</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>CheXpert-v1.0-small/valid/patient64545/study1/...</td>\n",
       "      <td>Female</td>\n",
       "      <td>55</td>\n",
       "      <td>Frontal</td>\n",
       "      <td>AP</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64545</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Path     Sex  Age  \\\n",
       "0  CheXpert-v1.0-small/valid/patient64541/study1/...    Male   73   \n",
       "1  CheXpert-v1.0-small/valid/patient64542/study1/...    Male   70   \n",
       "3  CheXpert-v1.0-small/valid/patient64543/study1/...    Male   85   \n",
       "4  CheXpert-v1.0-small/valid/patient64544/study1/...  Female   42   \n",
       "5  CheXpert-v1.0-small/valid/patient64545/study1/...  Female   55   \n",
       "\n",
       "  Frontal/Lateral AP/PA  No Finding  Enlarged Cardiomediastinum  Cardiomegaly  \\\n",
       "0         Frontal    AP         0.0                         1.0           1.0   \n",
       "1         Frontal    PA         0.0                         0.0           0.0   \n",
       "3         Frontal    AP         0.0                         1.0           0.0   \n",
       "4         Frontal    AP         1.0                         0.0           0.0   \n",
       "5         Frontal    AP         0.0                         1.0           0.0   \n",
       "\n",
       "   Lung Opacity  Lung Lesion  ...  Consolidation  Pneumonia  Atelectasis  \\\n",
       "0           1.0          0.0  ...            0.0        0.0          0.0   \n",
       "1           0.0          0.0  ...            0.0        0.0          0.0   \n",
       "3           1.0          0.0  ...            0.0        0.0          0.0   \n",
       "4           0.0          0.0  ...            0.0        0.0          0.0   \n",
       "5           1.0          0.0  ...            0.0        0.0          1.0   \n",
       "\n",
       "   Pneumothorax  Pleural Effusion  Pleural Other  Fracture  Support Devices  \\\n",
       "0           0.0               0.0            0.0       0.0              0.0   \n",
       "1           0.0               0.0            0.0       0.0              1.0   \n",
       "3           0.0               0.0            0.0       0.0              0.0   \n",
       "4           0.0               0.0            0.0       0.0              0.0   \n",
       "5           0.0               1.0            0.0       0.0              0.0   \n",
       "\n",
       "     PID  StudyID  \n",
       "0  64541        1  \n",
       "1  64542        1  \n",
       "3  64543        1  \n",
       "4  64544        1  \n",
       "5  64545        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./data/chexpert/train_plusMeta.csv')\n",
    "train_frontal = train[train['Frontal/Lateral']=='Frontal']\n",
    "valid = pd.read_csv('./data/chexpert/valid_plusMeta.csv')\n",
    "valid_frontal = valid[valid['Frontal/Lateral']=='Frontal']\n",
    "valid_frontal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training data with appropriate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 300\n",
    "imageDirRoot = 'C:/Users/3169dobbsp/Documents/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat = []\n",
    "sample = train_frontal.sample(n=1000,random_state=1)\n",
    "for index, row in sample.iterrows():\n",
    "    label = np.array([1,0])\n",
    "    if row['No Finding']==1:\n",
    "        label = np.array([0,1])\n",
    "    filepath = os.path.join(imageDirRoot,row['Path'])\n",
    "    img = Image.open(filepath)\n",
    "    img = img.convert('L')\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "    train_dat.append([np.array(img), label])\n",
    "\n",
    "plt.imshow(train_dat[22][0], cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary libraries for image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.models import Sequential \n",
    "from keras.layers import Conv2D, MaxPooling2D \n",
    "from keras.layers import Activation, Dropout, Flatten, Dense \n",
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, 5, padding='same', activation='relu', input_shape=(IMG_SIZE,IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = np.array([i[0] for i in train_dat]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "trainLabels = np.array([i[1] for i in train_dat])\n",
    "model.fit(trainImages, trainLabels, batch_size = 32, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dat = []\n",
    "sample = valid_frontal.sample(n=100,random_state=1)\n",
    "for index, row in sample.iterrows():\n",
    "    label = np.array([1,0])\n",
    "    if row['No Finding']==1:\n",
    "        label = np.array([0,1])\n",
    "    filepath = os.path.join(imageDirRoot,row['Path'])\n",
    "    img = Image.open(filepath)\n",
    "    img = img.convert('L')\n",
    "    img = img.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
    "    valid_dat.append([np.array(img), label])\n",
    "\n",
    "plt.imshow(valid_dat[28][0], cmap = 'gist_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages = np.array([i[0] for i in valid_dat]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "testLabels = np.array([i[1] for i in valid_dat])\n",
    "\n",
    "loss, acc = model.evaluate(testImages, testLabels, verbose = 0)\n",
    "print(acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Following Cell Is Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "seed=42\n",
    "# use generator for training data\n",
    "image_gen_train = ImageDataGenerator(\n",
    "                    rescale=1./255.,\n",
    "                    rotation_range=10,\n",
    "                    width_shift_range=.15,\n",
    "                    height_shift_range=.15,\n",
    "                    horizontal_flip=True,\n",
    "                    zoom_range=0.1\n",
    "                    )\n",
    "train_data_gen = image_gen_train.flow_from_dataframe(\n",
    "                    dataframe = train_frontal,\n",
    "                    directory=imageDirRoot,\n",
    "                    x_col=\"Path\",\n",
    "                    y_col=\"No Finding\",\n",
    "                    shuffle=True,\n",
    "                    batch_size=batch_size,\n",
    "                    seed=seed\n",
    "                    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "                    class_mode='sparse'\n",
    "                    )\n",
    "\n",
    "# use generator for validation data\n",
    "image_gen_val = ImageDataGenerator(rescale=1./255.)\n",
    "val_data_gen = image_gen_val.flow_from_dataframe(\n",
    "                    dataframe=valid_frontal,\n",
    "                    directory=imageDirRoot,\n",
    "                    x_col=\"Path\",\n",
    "                    y_col=\"No Finding\",\n",
    "                    shuffle=False,\n",
    "                    batch_size=batch_size,\n",
    "                    seed=seed\n",
    "                    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "                    class_mode='sparse'\n",
    "                    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
